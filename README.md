# Data Engineer

## Education
- B.S., Computer Science - Big Data Concentration | New York Institute of Technology (_May 2018_)
- A.S., Computer Science | New York Institute of Technology (_May 2015_)

## Work Experience
**Data Engineer II @ USAA (_April 2021 - Present_)**
- Risk Decision Engine project created $466M worth of value by strategically re-platforming all operational credit risk decisioning at USAA to a centralized platform
- Leading a distributed team of 7 developers in nationwide collaboration with 10+ teams and 300+ individuals ranging from business executives, program managers, product owners, information governance, business strategy teams, as well as internal and external vendor IT teams
- Identified discrepancies in **Data Quality & Compliance** and overhauled existing checks to exceed compliancy standards
- Multi-year experience building business-critical pipelines in strategies such as Credit Card, Deposits, Underwriting, Consumer Lending, Income, Military Rank, Customer, Bureau, and Sensitive PII/PCI/PHI data
- Communicated with vendors to reduce risks associated with business activities by actively identifying, measuring, monitoring, and generating reports
- Onboarded junior developers by conducting knowledge transfer sessions and one-on-one sessions on ETL, and Cloud environment
- **Data Warehouse Migration**
    - Leading cloud data warehouse migration into **Snowflake**
    - Configured S3 Cross-Account Bucket share with external vendor via IAM policies to create direct pipeline to Snowflake
    - Enbaled Point-forward loading into Snowflake
    - Migrated histrocial data from Hadoop to Snowflkae.
- **Kafka**
    - Re-designed Kafka Topic consumption pipeline by creating cross-team functionality
    - Reduced development from 4 weeks to 2 weeks and exceeded deadline expectations
    - Allowed ample time to design strategic solution for automation & scheduling



**Software Engineer @ HCL America Inc. (_August 2017 - April 2021_)**
- Designed core ETL pipeline which serves as backbone for credit card decisioning consisting of 4 unique sources and transformations like data cleansing, pivots, aggregations, format revision, derivations, deduplication, joins in IBM Datastage
- First project at USAA to utilize AWS S3 and real-time processing with Apache NiFi and consumption of data into Hadoop & Hive
- Designed Hadoop data pipeline with control & data governance checks on 30+ files
- Migrated 500 GB data in Hadoop from discovery servers to production
- Added GitLab capabilities, migrated and deployed code across multiple nodes
- **Schema Reconciliation & Evolution**
    - Independently improved developer bandwidth by decreasing wasted time and bottlenecks by automating monotonous tasks and improve efficiency by 80 hours per week (4 developers x 20hrs/each)
    - Created a script to compare a vetted data framework to incoming data and schema files to validate accuracy of data structure
    - Automated & logged daily reporting system that allowed stakeholder outreach for vendor accountability in failure events

## Skills
|Languages      |Data                           |ETL Tools                      |Cloud      |
|---            |---                            |---                            |---        |
|Python         |SQL, MySQL, DB2                |Hadoop, HDFS, Hive             |AWS - S3, EC2, Redshift, IAM |
|Bash,Shell     |Pandas, Numpy, Jupyter         |IBM Datastage, Control-M       |Snowflake  |
|               |Data Modeling                  |                               |           |

## Projects
### Expense Analysis